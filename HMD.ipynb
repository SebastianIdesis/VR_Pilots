{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a150ad-fba4-4868-a3a5-40c92a2c4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EPS = 1e-9\n",
    "\n",
    "def _robust_dt(t: np.ndarray) -> float:\n",
    "    \"\"\"Median dt, ignoring non-increasing timestamps.\"\"\"\n",
    "    t = np.asarray(t, dtype=float)\n",
    "    dt = np.diff(t)\n",
    "    dt = dt[dt > 0]\n",
    "    return float(np.median(dt)) if dt.size else np.nan\n",
    "\n",
    "def _mag(xyz: np.ndarray) -> np.ndarray:\n",
    "    return np.linalg.norm(xyz, axis=1)\n",
    "\n",
    "def _basic_stats(prefix: str, x: np.ndarray) -> dict:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return {f\"{prefix}_{k}\": np.nan for k in [\"mean\",\"std\",\"median\",\"p95\",\"max\",\"min\"]}\n",
    "    return {\n",
    "        f\"{prefix}_mean\": float(np.mean(x)),\n",
    "        f\"{prefix}_std\": float(np.std(x, ddof=0)),\n",
    "        f\"{prefix}_median\": float(np.median(x)),\n",
    "        f\"{prefix}_p95\": float(np.percentile(x, 95)),\n",
    "        f\"{prefix}_max\": float(np.max(x)),\n",
    "        f\"{prefix}_min\": float(np.min(x)),\n",
    "    }\n",
    "\n",
    "def _time_above(prefix: str, x: np.ndarray, thresholds: list[float]) -> dict:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    out = {}\n",
    "    if x.size == 0:\n",
    "        for thr in thresholds:\n",
    "            out[f\"{prefix}_pct_gt_{thr}\"] = np.nan\n",
    "        return out\n",
    "    for thr in thresholds:\n",
    "        out[f\"{prefix}_pct_gt_{thr}\"] = float(np.mean(x > thr) * 100.0)\n",
    "    return out\n",
    "\n",
    "def _jerk_from_signal(xyz: np.ndarray, dt: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Finite-diff derivative magnitude (jerk-like):\n",
    "      if xyz is acceleration -> jerk\n",
    "      if xyz is angular acceleration -> angular jerk\n",
    "    \"\"\"\n",
    "    if not np.isfinite(dt) or dt <= 0 or xyz is None:\n",
    "        return np.full((len(xyz),), np.nan) if xyz is not None else np.array([np.nan])\n",
    "    d = np.vstack([np.zeros(3), np.diff(xyz, axis=0)])\n",
    "    j = d / dt\n",
    "    return _mag(j)\n",
    "\n",
    "def _derive_acc_from_vel(v_xyz: np.ndarray, dt: float) -> np.ndarray:\n",
    "    \"\"\"Acceleration from velocity via finite differences.\"\"\"\n",
    "    if not np.isfinite(dt) or dt <= 0:\n",
    "        return np.full_like(v_xyz, np.nan)\n",
    "    dv = np.vstack([np.zeros(3), np.diff(v_xyz, axis=0)])\n",
    "    return dv / dt\n",
    "\n",
    "def extract_quest_round_features(\n",
    "    df: pd.DataFrame,\n",
    "    time_col: str = \"timestamp\",              # set to your Quest time column (e.g., \"lsl_timestamp\")\n",
    "    vel_cols: tuple[str, str, str] = (\"vx\", \"vy\", \"vz\"),\n",
    "    angvel_cols: tuple[str, str, str] = (\"wx\", \"wy\", \"wz\"),  # or (\"ang_vx\",\"ang_vy\",\"ang_vz\")\n",
    "    t_start: float | None = None,\n",
    "    t_end: float | None = None,\n",
    "    # thresholds (pick values that match your units)\n",
    "    speed_thresholds: list[float] = (0.3, 0.5, 1.0),          # m/s (if your v is m/s)\n",
    "    acc_thresholds: list[float] = (1.0, 2.0, 5.0),            # m/s^2\n",
    "    angspeed_thresholds: list[float] = (0.5, 1.0, 2.0),       # rad/s  (if your w is rad/s)\n",
    "    angacc_thresholds: list[float] = (1.0, 2.0, 5.0),         # rad/s^2\n",
    "    dropna: bool = True,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Per-round features from Quest kinematics:\n",
    "      - speed (|v|), linear acceleration (|a|), linear jerk (|da/dt|)\n",
    "      - angular speed (|w|), angular acceleration (|alpha|), angular jerk (|dalpha/dt|)\n",
    "      - component ranges/stds (optional but useful)\n",
    "      - time-above-threshold percentages\n",
    "\n",
    "    Returns a dict of scalar features for the selected time window.\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "\n",
    "    # time slice\n",
    "    if t_start is not None:\n",
    "        d = d[d[time_col] >= t_start]\n",
    "    if t_end is not None:\n",
    "        d = d[d[time_col] <= t_end]\n",
    "    d = d.sort_values(time_col)\n",
    "\n",
    "    out = {\"n_samples\": int(len(d))}\n",
    "\n",
    "    # not enough samples\n",
    "    if len(d) < 3:\n",
    "        # keep keys stable so you can build a dataframe later\n",
    "        base_keys = [\n",
    "            \"duration_s\",\"dt_median_s\",\n",
    "            \"speed_mean\",\"speed_p95\",\"acc_mean\",\"acc_p95\",\"jerk_p95\",\n",
    "            \"angspeed_mean\",\"angspeed_p95\",\"angacc_mean\",\"angacc_p95\",\"angjerk_p95\",\n",
    "        ]\n",
    "        out.update({k: np.nan for k in base_keys})\n",
    "        return out\n",
    "\n",
    "    # numeric arrays\n",
    "    t = pd.to_numeric(d[time_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "    dt = _robust_dt(t)\n",
    "    out[\"dt_median_s\"] = dt\n",
    "    out[\"duration_s\"] = float(t[-1] - t[0]) if np.isfinite(t[-1] - t[0]) else np.nan\n",
    "\n",
    "    v = d.loc[:, list(vel_cols)].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=float)\n",
    "    w = d.loc[:, list(angvel_cols)].apply(pd.to_numeric, errors=\"coerce\").to_numpy(dtype=float)\n",
    "\n",
    "    if dropna:\n",
    "        # drop rows where any required signal is NaN\n",
    "        mask = np.isfinite(t) & np.isfinite(v).all(axis=1) & np.isfinite(w).all(axis=1)\n",
    "        t, v, w = t[mask], v[mask], w[mask]\n",
    "        out[\"n_samples_after_dropna\"] = int(len(t))\n",
    "        if len(t) < 3:\n",
    "            out.update({k: np.nan for k in [\n",
    "                \"duration_s\",\"dt_median_s\",\n",
    "                \"speed_mean\",\"speed_p95\",\"acc_mean\",\"acc_p95\",\"jerk_p95\",\n",
    "                \"angspeed_mean\",\"angspeed_p95\",\"angacc_mean\",\"angacc_p95\",\"angjerk_p95\",\n",
    "            ]})\n",
    "            return out\n",
    "        dt = _robust_dt(t)\n",
    "        out[\"dt_median_s\"] = dt\n",
    "        out[\"duration_s\"] = float(t[-1] - t[0]) if np.isfinite(t[-1] - t[0]) else np.nan\n",
    "\n",
    "    # magnitudes\n",
    "    speed = _mag(v)\n",
    "    angspeed = _mag(w)\n",
    "\n",
    "    # derived accelerations\n",
    "    a = _derive_acc_from_vel(v, dt)\n",
    "    alpha = _derive_acc_from_vel(w, dt)  # angular acceleration\n",
    "\n",
    "    accmag = _mag(a)\n",
    "    angaccmag = _mag(alpha)\n",
    "\n",
    "    # jerks\n",
    "    jerk = _jerk_from_signal(a, dt)\n",
    "    angjerk = _jerk_from_signal(alpha, dt)\n",
    "\n",
    "    # stats\n",
    "    out.update(_basic_stats(\"speed\", speed))\n",
    "    out.update(_basic_stats(\"acc\", accmag))\n",
    "    out.update(_basic_stats(\"jerk\", jerk))\n",
    "\n",
    "    out.update(_basic_stats(\"angspeed\", angspeed))\n",
    "    out.update(_basic_stats(\"angacc\", angaccmag))\n",
    "    out.update(_basic_stats(\"angjerk\", angjerk))\n",
    "\n",
    "    # time above thresholds\n",
    "    out.update(_time_above(\"speed\", speed, list(speed_thresholds)))\n",
    "    out.update(_time_above(\"acc\", accmag, list(acc_thresholds)))\n",
    "    out.update(_time_above(\"angspeed\", angspeed, list(angspeed_thresholds)))\n",
    "    out.update(_time_above(\"angacc\", angaccmag, list(angacc_thresholds)))\n",
    "\n",
    "    # component variability (often useful for “movement style”)\n",
    "    for name, arr in [(\"v\", v), (\"w\", w), (\"a\", a), (\"alpha\", alpha)]:\n",
    "        out[f\"{name}_std_x\"] = float(np.nanstd(arr[:, 0]))\n",
    "        out[f\"{name}_std_y\"] = float(np.nanstd(arr[:, 1]))\n",
    "        out[f\"{name}_std_z\"] = float(np.nanstd(arr[:, 2]))\n",
    "        out[f\"{name}_range_x\"] = float(np.nanmax(arr[:, 0]) - np.nanmin(arr[:, 0]))\n",
    "        out[f\"{name}_range_y\"] = float(np.nanmax(arr[:, 1]) - np.nanmin(arr[:, 1]))\n",
    "        out[f\"{name}_range_z\"] = float(np.nanmax(arr[:, 2]) - np.nanmin(arr[:, 2]))\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_features_per_round(\n",
    "    df: pd.DataFrame,\n",
    "    round_col: str = \"round_id\",\n",
    "    **kwargs\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convenience wrapper:\n",
    "    groups by round_col and returns one feature-row per round.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for rid, g in df.groupby(round_col, sort=True):\n",
    "        feats = extract_quest_round_features(g, **kwargs)\n",
    "        feats[round_col] = rid\n",
    "        rows.append(feats)\n",
    "    return pd.DataFrame(rows).set_index(round_col, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca9d0f-ff75-40f0-9e51-5fffb6ca7b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78c8da8-f5e6-4691-a36a-8cfd61e37fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: your df has columns:\n",
    "# lsl_timestamp, vx, vy, vz, ang_vx, ang_vy, ang_vz, round_id\n",
    "\n",
    "feat_df = extract_features_per_round(\n",
    "    df,\n",
    "    round_col=\"round_id\",\n",
    "    time_col=\"lsl_timestamp\",\n",
    "    vel_cols=(\"vx\",\"vy\",\"vz\"),\n",
    "    angvel_cols=(\"ang_vx\",\"ang_vy\",\"ang_vz\"),\n",
    "    # thresholds matching your units (edit as needed)\n",
    "    speed_thresholds=[0.3, 0.5, 1.0],\n",
    "    angspeed_thresholds=[0.5, 1.0, 2.0],  # rad/s\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
